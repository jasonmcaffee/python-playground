{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/unum-cloud/uform-gen/tree/main\n",
    "!huggingface-cli download unum-cloud/uform-gen --cache-dir \"C:\\shared-drive\\llm_models\\uform-gen\"\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T03:41:41.576625Z",
     "start_time": "2024-05-29T03:40:24.586435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# need torch for cuda version 12.1 since that's what I have installed\n",
    "#!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121\n",
    "# !pip3 install torch==2.1.1+cu121 torchvision==0.17.2+cu121 torchaudio==2.1.1 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121"
   ],
   "id": "2e39dce07c38da14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (2.4.0.dev20240527+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp310-cp310-win_amd64.whl (2413.3 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0.dev20240527+cu121\n",
      "    Can't uninstall 'torch'. No files were found to uninstall.\n",
      "Successfully installed torch-2.3.0+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    WARNING: No metadata found in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T03:52:01.767231Z",
     "start_time": "2024-05-29T03:52:01.704252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "!python --version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Print the CUDA version\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "num_devices = torch.cuda.device_count()\n",
    "for device_id in range(num_devices):\n",
    "    device_name = torch.cuda.get_device_name(device_id)\n",
    "    print(f\"Device ID: {device_id}, Name: {device_name}\")"
   ],
   "id": "792b31be385e638f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "Python 3.10.6\n",
      "PyTorch version: 2.3.0+cu121\n",
      "CUDA version: 12.1\n",
      "Device ID: 0, Name: NVIDIA GeForce RTX 3090\n",
      "Device ID: 1, Name: NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T03:46:23.795107Z",
     "start_time": "2024-05-29T03:46:23.158095Z"
    }
   },
   "cell_type": "code",
   "source": "!pip show flash_attn",
   "id": "6ba48f96b0336a17",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: flash_attn\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T01:11:50.620816Z",
     "start_time": "2024-05-29T01:11:48.376065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!pip install uform\n",
    "# !pip install torchvision\n",
    "!pip install safetensors"
   ],
   "id": "ac619f06ff7dd9ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: safetensors in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (0.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T03:53:09.804709Z",
     "start_time": "2024-05-29T03:53:01.651275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from uform.gen_model import VLMForCausalLM, VLMProcessor\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "device_id = 0 # 1 runs out of memory\n",
    "torch.cuda.set_device(device_id)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device is {device}')\n",
    "model = AutoModel.from_pretrained(\"unum-cloud/uform-gen2-qwen-500m\", trust_remote_code=True).to(device)\n",
    "processor = AutoProcessor.from_pretrained(\"unum-cloud/uform-gen2-qwen-500m\", trust_remote_code=True)\n",
    "# \n",
    "# prompt = \"Describe this picture\"\n",
    "# image = Image.open(\"panda.png\")\n",
    "# \n",
    "# inputs = processor(text=[prompt], images=[image], return_tensors=\"pt\")\n",
    "# with torch.inference_mode():\n",
    "#      output = model.generate(\n",
    "#         **inputs,\n",
    "#         do_sample=False,\n",
    "#         use_cache=True,\n",
    "#         max_new_tokens=256,\n",
    "#         eos_token_id=151645,\n",
    "#         pad_token_id=processor.tokenizer.pad_token_id\n",
    "#     )\n",
    "# \n",
    "# prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "# decoded_text = processor.batch_decode(output[:, prompt_len:])[0]\n",
    "# \n",
    "# print(decoded_text)\n"
   ],
   "id": "868c835e30c0b16e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d938942ee1ed41ea9e7ad72daff949b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T00:05:48.090632Z",
     "start_time": "2024-05-30T00:05:48.077907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_image(image_path:str, prompt:str):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    inputs = processor(text=[prompt], images=[image], return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "         output = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            use_cache=True,\n",
    "            max_new_tokens=256,\n",
    "            eos_token_id=151645,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    decoded_text = processor.batch_decode(output[:, prompt_len:])[0]\n",
    "    \n",
    "    # print(decoded_text)\n",
    "    return decoded_text"
   ],
   "id": "35771031dd69106f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T00:09:08.041532Z",
     "start_time": "2024-05-30T00:09:02.332307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = '''You are an expert in providing in depth analysis of images. \n",
    "You provide nuanced details of the objects, lighting, colors, actions, time, place, feeling, smells, and other details.\n",
    "Please describe the image in as much detail as possible. Identify any people, places, or things in the image. \n",
    "Describe the facial expressions and emotions of any people present.\n",
    "\n",
    "List and describe all objects in the scene, including details such as color, shape, size, texture, and feel.\n",
    "\n",
    "Specify the time of day depicted in the image and provide an approximate year or historical period, if possible.\n",
    "\n",
    "Identify the country, city, building, or specific location where the image is set.\n",
    "\n",
    "Indicate whether the image is a painting, picture, drawing, or another type of visual representation.\n",
    "\n",
    "Describe the overall vibe or emotion that the image conveys.\n",
    "\n",
    "Detail any actions taking place in the image.\n",
    "\n",
    "Transcribe any visible text in the image.\n",
    "\n",
    "Mention any other notable features or elements that contribute to the overall understanding of the image.\n",
    "\n",
    "'''\n",
    "analyze_image(\"panda.png\", prompt)"
   ],
   "id": "9c2282f37faab4c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The image depicts a playful and whimsical scene featuring a giant panda bear wearing an astronaut outfit. The panda bear is seated at a wooden table, surrounded by various objects. The table is adorned with a plate of noodles, a cup of coffee, and a pair of chopsticks. The panda bear is wearing an astronaut uniform, complete with an American flag on its back. The astronaut uniform is white with blue accents, and the panda bear's outfit is made of a material that resembles a space suit. The panda bear's eyes are closed, and its ears are perked up, giving it a curious and playful expression. The panda bear's face is black and white, and its ears are black as well. The table is made of wood and has a brown color. The background consists of a wall with white tiles, and there is a window with blinds. The overall atmosphere of the image is light-hearted and fun, with the panda bear appearing to be enjoying a meal in a unique and imaginative setting.<|im_end|>\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T00:09:56.134709Z",
     "start_time": "2024-05-30T00:09:56.120713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "def analyze_image_stream(image_path: str, prompt: str):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    inputs = processor(text=[prompt], images=[image], return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    class StreamStoppingCriteria(StoppingCriteria):\n",
    "        def __init__(self, prompt_length):\n",
    "            self.prompt_length = prompt_length\n",
    "            self.generated_text = \"\"\n",
    "        \n",
    "        def __call__(self, input_ids, scores, **kwargs):\n",
    "            new_token_id = input_ids[0, -1].item()\n",
    "            new_token_text = processor.tokenizer.decode([new_token_id])\n",
    "            self.generated_text += new_token_text\n",
    "            print(new_token_text, end='', flush=True)  # Print without newline and flush immediately\n",
    "            # You can add custom stopping conditions here if needed\n",
    "            return False\n",
    "\n",
    "    stopping_criteria = StoppingCriteriaList([StreamStoppingCriteria(inputs[\"input_ids\"].shape[1])])\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            use_cache=True,\n",
    "            max_new_tokens=1024,\n",
    "            eos_token_id=151645,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            stopping_criteria=stopping_criteria\n",
    "        )\n",
    "\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    decoded_text = stopping_criteria[0].generated_text\n",
    "    \n",
    "    # return decoded_text"
   ],
   "id": "3629782cf1f05852",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T00:11:33.920430Z",
     "start_time": "2024-05-30T00:11:24.076430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = '''You are an expert in providing in depth analysis of images. \n",
    "You provide nuanced details of the subjects, objects, lighting, colors, actions, time, place, feeling, smells, and other details. i.e. You should provide details on who, what, why, when, where.\n",
    "Please provide an in depth analysis of the image.\n",
    "'''\n",
    "analyze_image_stream(\"panda.png\", prompt)"
   ],
   "id": "78fde0400ce8e647",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image features a playful scene of a panda bear wearing an astronaut suit, sitting at a table. The panda bear is quite large, occupying a significant portion of the image. It has a black and white coat, with a distinct black nose and ears. The panda bear is wearing a white astronaut suit, which includes an American flag on the back. The suit is also adorned with a blue and white stripe, and the bear's arms are adorned with a pair of black and white paws.\n",
      "The panda bear is seated on a brown wooden chair, which is positioned in front of a table. The table is filled with various objects. On the table, there is a plate with noodles, which the panda bear is eating. There is also a cup with a straw in it, and a pair of chopsticks placed on the table.\n",
      "The background of the image features a wall with white tiles. The wall is partially visible, and it appears to be a part of a larger room. The wall has a brown color, and there is a window with a white frame. The window is located behind the panda bear, and it provides a view of the room.\n",
      "The lighting in the image is bright, and it creates a contrast between the panda bear and the other objects on the table. The panda bear's black and white coat stands out against the brown of the table and chair, and the white wall provides a neutral background.\n",
      "Overall, the image captures a playful and whimsical scene, with the panda bear dressed up as an astronaut and enjoying a meal at a table. The combination of the astronaut suit, noodles, chopsticks, and the window adds to the humor and humor of the image.<|im_end|>"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T00:24:45.210362Z",
     "start_time": "2024-05-30T00:24:35.653195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = '''You are an expert in providing in depth analysis of images. \n",
    "You provide nuanced details of the subjects, objects, lighting, colors, actions, time, place, feeling, smells, and other details. i.e. You should provide details on who, what, why, when, where.\n",
    "Please provide an in depth analysis of the image.\n",
    "'''\n",
    "analyze_image_stream(\"C:\\\\shared-drive\\\\llm_models\\\\ComfyUI_windows_portable\\\\ComfyUI\\\\output\\\\ComfyUI_00192_.png\", prompt)"
   ],
   "id": "e91613d40b5d56d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image captures a young woman standing in a park. The woman is the central figure, occupying a significant portion of the image. She is dressed in a green top and a white skirt, both of which are part of a pair. The top is a bright green, and the skirt is a contrasting white. The woman's hair is long and dark, and she is wearing a necklace around her neck. Her face is turned towards the camera, giving a direct gaze. Her left hand is on her hip, and her right hand is in her pocket.\n",
      "The park is lush and green, with trees scattered around. The trees are tall and leafy, and their trunks are visible. The ground is covered in grass, and there are patches of dirt visible as well. The woman is standing on a path that is surrounded by the trees. The path is well-maintained, and it seems to be a quiet and peaceful area.\n",
      "The lighting in the image is bright and natural, with sunlight filtering through the trees. The sunlight illuminates the woman's face and the background, creating a warm and inviting atmosphere. The colors in the image are vibrant and natural, with the green of the top and skirt, the white of the skirt, and the green of the grass and trees. The woman's outfit is also quite eye-catching, with the green top and white skirt standing out against the green grass and the white skirt.\n",
      "Overall, the image captures a serene moment in a park, with the woman as the central figure, dressed in a stylish outfit, and surrounded by nature. The bright sunlight and natural colors create a beautiful and inviting atmosphere.<|im_end|>"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T01:34:03.693548Z",
     "start_time": "2024-05-31T01:33:59.858262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = '''\n",
    "You are an expert in providing in depth analysis of images. \n",
    "You provide nuanced details of the subjects, objects, lighting, colors, actions, time, place, feeling, smells, and other details. i.e. You should provide details on who, what, why, when, where.\n",
    "Please provide an in depth analysis of the image.\n",
    "'''\n",
    "analyze_image_stream(\"Drivers_ License_1.jpg\", prompt)"
   ],
   "id": "54b58bed18ef03bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a 2012 Pennsylvania State University football credit card. The card is in a light blue color and features a photo of a young man, who is smiling. The man is wearing a green shirt and has short brown hair. The card has the university's logo and the date \"09/01/2012\" written on it. The card also has the university's phone number and the university's website address. The card is in good condition and is clearly labeled with the credit card number, university name, and date of issuance.<|im_end|>"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1d66d31a0f7ff58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
