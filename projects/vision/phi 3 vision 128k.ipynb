{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "THIS DOES NOT WORK DUE TO LACK OF FLASH ATTENTION SUPPORT ON WINDOWS.",
   "id": "29147abaf4754afe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T00:42:12.732139Z",
     "start_time": "2024-05-28T00:42:12.712148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(os.environ.get('CUDA_HOME'))"
   ],
   "id": "2c712942dd54b436",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T00:33:09.858627Z",
     "start_time": "2024-05-28T00:32:31.113597Z"
    }
   },
   "source": [
    "# import os\n",
    "# os.environ['CUDA_HOME'] = r'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1'\n",
    "\n",
    "# !pip install torch==2.3.0\n",
    "# !pip install wheel\n",
    "# !pip install flash_attn==2.5.8\n",
    "# !pip install numpy==1.24.4\n",
    "# !pip install Pillow==10.3.0\n",
    "# !pip install Requests==2.31.0\n",
    "# !pip install torchvision==0.18.0\n",
    "# !pip install transformers==4.40.2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.3.0\n",
      "  Obtaining dependency information for torch==2.3.0 from https://files.pythonhosted.org/packages/2e/f7/503bab04f4e7a0a43f2ff05c3635cee9dfcf2e09656020d29502b87a94a3/torch-2.3.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading torch-2.3.0-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch==2.3.0)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/41/24/0b023b6537dfc9bae2c779353998e3e99ac7dfff4222fc6126650e93c3f3/filelock-3.14.0-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch==2.3.0) (4.12.0)\n",
      "Collecting sympy (from torch==2.3.0)\n",
      "  Obtaining dependency information for sympy from https://files.pythonhosted.org/packages/d2/05/e6600db80270777c4a64238a98d442f0fd07cc8915be2a1c16da7f2b9e74/sympy-1.12-py3-none-any.whl.metadata\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.3.0)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch==2.3.0) (3.1.4)\n",
      "Collecting fsspec (from torch==2.3.0)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/ba/a3/16e9fe32187e9c8bc7f9b7bcd9728529faa725231a0c96f2f98714ff2fc5/fsspec-2024.5.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch==2.3.0)\n",
      "  Obtaining dependency information for mkl<=2021.4.0,>=2021.1.1 from https://files.pythonhosted.org/packages/fe/1c/5f6dbf18e8b73e0a5472466f0ea8d48ce9efae39bd2ff38cebf8dce61259/mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0)\n",
      "  Obtaining dependency information for intel-openmp==2021.* from https://files.pythonhosted.org/packages/6f/21/b590c0cc3888b24f2ac9898c41d852d7454a1695fbad34bee85dba6dc408/intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0)\n",
      "  Obtaining dependency information for tbb==2021.* from https://files.pythonhosted.org/packages/7b/2d/1e1c70fae8ace27e6200fb71c2372a9aeac2baba474b1609d7d466e969b4/tbb-2021.12.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from jinja2->torch==2.3.0) (2.1.5)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.3.0)\n",
      "  Obtaining dependency information for mpmath>=0.19 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.3.0-cp310-cp310-win_amd64.whl (159.8 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 153.6/316.1 kB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 307.2/316.1 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 316.1/316.1 kB 3.3 MB/s eta 0:00:00\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, networkx, mkl, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.5.0 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 sympy-1.12 tbb-2021.12.0 torch-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash_attn==2.5.8\n",
      "  Using cached flash_attn-2.5.8.tar.gz (2.5 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  C:\\Users\\jason\\AppData\\Local\\Temp\\pip-install-gwo13q66\\flash-attn_e51ff9ee00b64b5d86d3bbc6b6417eef\\setup.py:78: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "    warnings.warn(\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\jason\\AppData\\Local\\Temp\\pip-install-gwo13q66\\flash-attn_e51ff9ee00b64b5d86d3bbc6b6417eef\\setup.py\", line 134, in <module>\n",
      "      CUDAExtension(\n",
      "    File \"C:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1077, in CUDAExtension\n",
      "      library_dirs += library_paths(cuda=True)\n",
      "    File \"C:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1211, in library_paths\n",
      "      paths.append(_join_cuda_home(lib_dir))\n",
      "    File \"C:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 2419, in _join_cuda_home\n",
      "      raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \n",
      "  \n",
      "  torch.__version__  = 2.3.0+cpu\n",
      "  \n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T01:24:29.749731Z",
     "start_time": "2024-05-28T01:24:27.178048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM \n",
    "from transformers import AutoProcessor \n",
    "\n",
    "model_path = \"C:\\\\shared-drive\\\\llm_models\\\\Phi-3-vision-128k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"cuda\", trust_remote_code=True, torch_dtype=\"auto\")\n",
    "\n",
    "processor_path = \"C:\\\\shared-drive\\\\llm_models\\\\Phi-3-vision-128k-instruct\"\n",
    "processor = AutoProcessor.from_pretrained(processor_path, trust_remote_code=True)\n",
    "\n",
    "messages = [ \n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"The chart displays the percentage of respondents who agree with various statements about their preparedness for meetings. It shows five categories: 'Having clear and pre-defined goals for meetings', 'Knowing where to find the information I need for a meeting', 'Understanding my exact role and responsibilities when I'm invited', 'Having tools to manage admin tasks like note-taking or summarization', and 'Having more focus time to sufficiently prepare for meetings'. Each category has an associated bar indicating the level of agreement, measured on a scale from 0% to 100%.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"Provide insightful questions to spark discussion.\"} \n",
    "] \n",
    "\n",
    "url = \"https://assets-c4akfrf5b4d3f4b7.z01.azurefd.net/assets/2024/04/BMDataViz_661fb89f3845e.png\" \n",
    "image = Image.open(requests.get(url, stream=True).raw) \n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = processor(prompt, [image], return_tensors=\"pt\").to(\"cuda:0\") \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args) \n",
    "\n",
    "# remove input tokens \n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "print(response)\n"
   ],
   "id": "1587e50a9f13bb",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoProcessor \n\u001B[0;32m      6\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mshared-drive\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mllm_models\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPhi-3-vision-128k-instruct\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m processor_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mshared-drive\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mllm_models\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mPhi-3-vision-128k-instruct\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     10\u001B[0m processor \u001B[38;5;241m=\u001B[39m AutoProcessor\u001B[38;5;241m.\u001B[39mfrom_pretrained(processor_path, trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:550\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_remote_code \u001B[38;5;129;01mand\u001B[39;00m trust_remote_code:\n\u001B[0;32m    549\u001B[0m     class_ref \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mauto_map[\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m]\n\u001B[1;32m--> 550\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m get_class_from_dynamic_module(\n\u001B[0;32m    551\u001B[0m         class_ref, pretrained_model_name_or_path, code_revision\u001B[38;5;241m=\u001B[39mcode_revision, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    552\u001B[0m     )\n\u001B[0;32m    553\u001B[0m     _ \u001B[38;5;241m=\u001B[39m hub_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_revision\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(pretrained_model_name_or_path):\n",
      "File \u001B[1;32mC:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\transformers\\dynamic_module_utils.py:489\u001B[0m, in \u001B[0;36mget_class_from_dynamic_module\u001B[1;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001B[0m\n\u001B[0;32m    487\u001B[0m     code_revision \u001B[38;5;241m=\u001B[39m revision\n\u001B[0;32m    488\u001B[0m \u001B[38;5;66;03m# And lastly we get the class inside our newly created module\u001B[39;00m\n\u001B[1;32m--> 489\u001B[0m final_module \u001B[38;5;241m=\u001B[39m \u001B[43mget_cached_module_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.py\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode_revision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m get_class_in_module(class_name, final_module)\n",
      "File \u001B[1;32mC:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\transformers\\dynamic_module_utils.py:315\u001B[0m, in \u001B[0;36mget_cached_module_file\u001B[1;34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;66;03m# Check we have all the requirements in our environment\u001B[39;00m\n\u001B[1;32m--> 315\u001B[0m modules_needed \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_imports\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresolved_module_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;66;03m# Now we move the module inside our cached dynamic modules.\u001B[39;00m\n\u001B[0;32m    318\u001B[0m full_submodule \u001B[38;5;241m=\u001B[39m TRANSFORMERS_DYNAMIC_MODULE_NAME \u001B[38;5;241m+\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msep \u001B[38;5;241m+\u001B[39m submodule\n",
      "File \u001B[1;32mC:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\transformers\\dynamic_module_utils.py:180\u001B[0m, in \u001B[0;36mcheck_imports\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m    177\u001B[0m         missing_packages\u001B[38;5;241m.\u001B[39mappend(imp)\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_packages) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 180\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m    181\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis modeling file requires the following packages that were not found in your environment: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    182\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(missing_packages)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Run `pip install \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(missing_packages)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    183\u001B[0m     )\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m get_relative_imports(filename)\n",
      "\u001B[1;31mImportError\u001B[0m: This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b661e1744cf98c50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
