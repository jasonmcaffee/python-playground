{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T01:22:42.544921Z",
     "start_time": "2024-05-28T01:22:37.542996Z"
    }
   },
   "source": [
    "# Download a windows release from here\n",
    "# https://github.com/jllllll/flash-attention/releases/\n",
    "# e.g https://github.com/jllllll/flash-attention/releases/download/v2.4.2/flash_attn-2.4.2+cu121torch2.1cxx11abiFALSE-cp310-cp310-win_amd64.whl\n",
    "\n",
    "!pip install C:\\shared-drive\\llm_models\\flash_attn-2.4.2+cu121torch2.1cxx11abiFALSE-cp310-cp310-win_amd64.whl"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\shared-drive\\llm_models\\flash_attn-2.4.2+cu121torch2.1cxx11abifalse-cp310-cp310-win_amd64.whl\n",
      "Requirement already satisfied: torch in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (2.3.0)\n",
      "Collecting einops (from flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE)\n",
      "  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/44/5a/f0b9ad6c0a9017e62d4735daaeb11ba3b6c009d69a26141b258cd37b5588/einops-0.8.0-py3-none-any.whl.metadata\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (24.0)\n",
      "Collecting ninja (from flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE)\n",
      "  Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/b6/2f/a3bc50fa63fc4fe9348e15b53dc8c87febfd4e0c660fcf250c4b19a3aa3b/ninja-1.11.1.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from jinja2->torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from sympy->torch->flash-attn==2.4.2+cu121torch2.1cxx11abiFALSE) (1.3.0)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-win_amd64.whl (312 kB)\n",
      "Installing collected packages: ninja, einops, flash-attn\n",
      "Successfully installed einops-0.8.0 flash-attn-2.4.2 ninja-1.11.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T01:22:54.013284Z",
     "start_time": "2024-05-28T01:22:51.949248Z"
    }
   },
   "cell_type": "code",
   "source": "!pip show flash-attn",
   "id": "acf9e1f093f48232",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: flash_attn\n",
      "Version: 2.4.2\n",
      "Summary: Flash Attention: Fast and Memory-Efficient Exact Attention\n",
      "Home-page: https://github.com/Dao-AILab/flash-attention\n",
      "Author: Tri Dao\n",
      "Author-email: trid@cs.stanford.edu\n",
      "License: \n",
      "Location: c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\n",
      "Requires: einops, ninja, packaging, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T01:25:17.169555Z",
     "start_time": "2024-05-28T01:25:14.928981Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install flash_attn",
   "id": "6cbe43148d4d1078",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash_attn in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: torch in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from flash_attn) (2.3.0)\n",
      "Requirement already satisfied: einops in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from flash_attn) (0.8.0)\n",
      "Requirement already satisfied: packaging in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from flash_attn) (24.0)\n",
      "Requirement already satisfied: ninja in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from flash_attn) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash_attn) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash_attn) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash_attn) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash_attn) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash_attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash_attn) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from torch->flash_attn) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->flash_attn) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->flash_attn) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from jinja2->torch->flash_attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages (from sympy->torch->flash_attn) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T01:25:56.078022Z",
     "start_time": "2024-05-28T01:25:54.264954Z"
    }
   },
   "cell_type": "code",
   "source": "from flash_attn import flash_attn_qkvpacked_func, flash_attn_func",
   "id": "7ef2ebfc91bb16e1",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing flash_attn_2_cuda: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mflash_attn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m flash_attn_qkvpacked_func, flash_attn_func\n",
      "File \u001B[1;32mC:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\flash_attn\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.4.2\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mflash_attn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflash_attn_interface\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     flash_attn_func,\n\u001B[0;32m      5\u001B[0m     flash_attn_kvpacked_func,\n\u001B[0;32m      6\u001B[0m     flash_attn_qkvpacked_func,\n\u001B[0;32m      7\u001B[0m     flash_attn_varlen_func,\n\u001B[0;32m      8\u001B[0m     flash_attn_varlen_kvpacked_func,\n\u001B[0;32m      9\u001B[0m     flash_attn_varlen_qkvpacked_func,\n\u001B[0;32m     10\u001B[0m     flash_attn_with_kvcache,\n\u001B[0;32m     11\u001B[0m )\n",
      "File \u001B[1;32mC:\\shared-drive\\dev\\python-playground\\venv\\lib\\site-packages\\flash_attn\\flash_attn_interface.py:10\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# isort: off\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# We need to import the CUDA kernels after importing torch\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mflash_attn_2_cuda\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mflash_attn_cuda\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# isort: on\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_block_size\u001B[39m(device, head_dim, is_dropout, is_causal):\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;66;03m# This should match the block sizes in the CUDA kernel\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing flash_attn_2_cuda: The specified module could not be found."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d8a1d4b76ad73658"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
