{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_for_knowledge_retrieval.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import openai\n",
    "from projects.chatgpt.agents.LLMFunctionsAgent import LLMFunctionsAgent\n",
    "\n",
    "# configure the client's secret key\n",
    "with open('secret-key.txt', 'r') as file:\n",
    "    secret_key = file.read().strip()\n",
    "openai.api_key = secret_key\n",
    "\n",
    "max_tokens = 4092\n",
    "\n",
    "# automatically reload changes to imports\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-26T22:53:19.305980Z",
     "start_time": "2023-12-26T22:53:18.886266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import time\n",
    "def prompt(question):\n",
    "    start_time_seconds = time.time()\n",
    "    print(f\"asking chatgpt: {question}\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", #\"text-davinci-003\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions accurately, without making up facts.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "    )\n",
    "    # print(response)\n",
    "    choices = response.choices\n",
    "    choice = choices[0]\n",
    "    message = choice['message']\n",
    "    answer = message['content']\n",
    "    print(answer)\n",
    "    print(f\"answer received in {time.time() - start_time_seconds} seconds.\")\n",
    "\n",
    "def stream_prompt(question):\n",
    "    start_time_seconds = time.time()\n",
    "    print(f\"asking chatgpt: {question}\")\n",
    "    stream = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", #\"text-davinci-003\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions accurately, without making up facts.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    for output in stream:\n",
    "        choices = output['choices']\n",
    "        choice = choices[0]\n",
    "        delta = choice['delta']\n",
    "        if 'content' in delta:\n",
    "            print(delta['content'], end='')\n",
    "    print()\n",
    "    print(f\"answer received in {time.time() - start_time_seconds} seconds.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-26T22:53:34.147506Z",
     "start_time": "2023-12-26T22:53:34.137424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asking chatgpt: \n",
      "Who is Jason McAffee?\n",
      "I couldn't find any specific information about a person named Jason McAffee. It's possible that he is a private individual or not widely known in public sources.\n",
      "answer received in 1.4250340461730957 seconds.\n"
     ]
    }
   ],
   "source": [
    "stream_prompt(\"\"\"\n",
    "Who is Jason McAffee?\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-26T22:53:42.772698Z",
     "start_time": "2023-12-26T22:53:41.336784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "\n",
      "---- found function with tool_data: find_financial_transactions\n",
      "---- found function with tool_data: get_user_details\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "llm_functions_agent = LLMFunctionsAgent(openai=openai)\n",
    "\n",
    "def inference(question):\n",
    "    llm_functions_agent.inference(question)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-15T02:25:45.639487Z",
     "start_time": "2023-12-15T02:25:45.550780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- inference ------------\n",
      "sending messages: [{'role': 'system', 'content': 'You are a helpful assistant that answers questions accurately, without making up facts.'}, {'role': 'user', 'content': '\\nWho is user Jason McAffee?\\n'}]\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAPIRemovedInV1\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mautoreload\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;43mWho is user Jason McAffee?\u001B[39;49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m, in \u001B[0;36minference\u001B[0;34m(question)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minference\u001B[39m(question):\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mllm_functions_agent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/python-playground-v2/projects/chatgpt/agents/LLMFunctionsAgent.py:41\u001B[0m, in \u001B[0;36mLLMFunctionsAgent.inference\u001B[0;34m(self, question, conversation, start_time_seconds)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msending messages: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmessages\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# call chatgpt\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtools\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# print(response)\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# add the response to our conversation.  we may need to pass it back to chatgpt if a function is called.\u001B[39;00m\n\u001B[1;32m     45\u001B[0m conversation\u001B[38;5;241m.\u001B[39madd_chatgpt_response_to_messages(response)\n",
      "File \u001B[0;32m~/git/python-playground-v2/venv/lib/python3.9/site-packages/openai/lib/_old_api.py:39\u001B[0m, in \u001B[0;36mAPIRemovedInV1Proxy.__call__\u001B[0;34m(self, *_args, **_kwargs)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m_args: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m APIRemovedInV1(symbol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_symbol)\n",
      "\u001B[0;31mAPIRemovedInV1\u001B[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "inference(\"\"\"\n",
    "Who is user Jason McAffee?\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-15T02:25:50.875741Z",
     "start_time": "2023-12-15T02:25:50.763213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T23:11:43.055813Z",
     "start_time": "2023-11-26T23:11:43.025589Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
