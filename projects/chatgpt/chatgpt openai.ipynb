{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# configure the client's secret key\n",
    "with open('secret-key.txt', 'r') as file:\n",
    "    secret_key = file.read().strip()\n",
    "openai.api_key = secret_key\n",
    "\n",
    "max_tokens = 4092"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import time\n",
    "def prompt(question):\n",
    "    start_time_seconds = time.time()\n",
    "    print(f\"asking chatgpt: {question}\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", #\"text-davinci-003\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions accurately, without making up facts.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "    )\n",
    "    # print(response)\n",
    "    choices = response.choices\n",
    "    choice = choices[0]\n",
    "    message = choice['message']\n",
    "    answer = message['content']\n",
    "    print(answer)\n",
    "    print(f\"answer received in {time.time() - start_time_seconds} seconds.\")\n",
    "\n",
    "def stream_prompt(question):\n",
    "    start_time_seconds = time.time()\n",
    "    print(f\"asking chatgpt: {question}\")\n",
    "    stream = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", #\"text-davinci-003\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions accurately, without making up facts.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    for output in stream:\n",
    "        choices = output['choices']\n",
    "        choice = choices[0]\n",
    "        delta = choice['delta']\n",
    "        if 'content' in delta:\n",
    "            print(delta['content'], end='')\n",
    "    print()\n",
    "    print(f\"answer received in {time.time() - start_time_seconds} seconds.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asking chatgpt: \n",
      "What is a camel?\n",
      "\n",
      "A camel is a large mammal with a humped back, long legs, and a long neck. It is native to the deserts of Africa and Asia and is well adapted to living in hot and arid conditions. Camels are known for their ability to store water in their humps, enabling them to survive in environments with limited water sources. They are often used as pack animals and are also raised for their milk, meat, and hair.\n",
      "answer received in 10.847567319869995 seconds.\n"
     ]
    }
   ],
   "source": [
    "stream_prompt(\"\"\"\n",
    "What is a camel?\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_for_knowledge_retrieval.ipynb\n",
    "import json\n",
    "\n",
    "def get_function_calls_details_from_llm_response(response):\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.get('tool_calls')\n",
    "    results = None\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        results = []\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            arguments = tool_call.function.arguments\n",
    "            result = {\n",
    "                \"function_name\": function_name,\n",
    "                \"arguments\": arguments,\n",
    "                # data needed for subsequent calls to chatgpt\n",
    "                \"metadata\": {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": None, # todo: populate this once the function has been executed.\n",
    "                },\n",
    "            }\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "def function_call_prompt(question):\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_user_details\",\n",
    "                \"description\": \"Retrieves information for a user based on the combination of their first and last names.  It returns information about the user's age, location, and profession.\",\n",
    "                \"parameters\":{\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"first_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"First name of the user to get details of.\"\n",
    "                        },\n",
    "                        \"last_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Last name of the user to get details of.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"first_name\", \"last_name\"]\n",
    "                }\n",
    "            },\n",
    "\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    start_time_seconds = time.time()\n",
    "    print(f\"asking chatgpt: {question}\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions accurately, without making up facts.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        tools=tools\n",
    "    )\n",
    "    print(response)\n",
    "    functions = get_function_calls_details_from_llm_response(response)\n",
    "    if functions is not None:\n",
    "        for function in functions:\n",
    "            if function['function_name'] == 'get_user_details':\n",
    "                content = get_user_details(function['arguments'])\n",
    "                function['metadata']['content'] = content\n",
    "\n",
    "    print(f\"answer received in {time.time() - start_time_seconds} seconds.\")\n",
    "\n",
    "# function that will be called, based on the LLM's response, which will indicate that it wants the function to be called, along with the arguments\n",
    "# arguments are a json string.  e.g. '{\"first_name\": \"Jason\", \"last_name: \"McAffee\"}'\n",
    "def get_user_details(args):\n",
    "    arguments = json.loads(args)\n",
    "    print(f\"get_user_details function called with arguments first_name: {arguments['first_name']}, last_name: {arguments['last_name']}\")\n",
    "    response = {\n",
    "        \"age\": 44,\n",
    "        \"location\": {\n",
    "            \"state\": \"Utah\"\n",
    "        },\n",
    "        \"profession\": \"Software Engineer\"\n",
    "    }\n",
    "    return response"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asking chatgpt: \n",
      "Who is user Jason McAffee?\n",
      "\n",
      "{\n",
      "  \"id\": \"chatcmpl-8OdsAEvqPHUWMlLYShPRlc90SizCy\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1700883834,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_HnsHtNPVKC6rVYXYEG2duSs3\",\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"get_user_details\",\n",
      "              \"arguments\": \"{\\n  \\\"first_name\\\": \\\"Jason\\\",\\n  \\\"last_name\\\": \\\"McAffee\\\"\\n}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 123,\n",
      "    \"completion_tokens\": 27,\n",
      "    \"total_tokens\": 150\n",
      "  }\n",
      "}\n",
      "get_user_details function called with arguments first_name: Jason, last_name: McAffee\n",
      "answer received in 3.895408868789673 seconds.\n"
     ]
    }
   ],
   "source": [
    "function_call_prompt(\"\"\"\n",
    "Who is user Jason McAffee?\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asking chatgpt: \n",
      "What is a camel?\n",
      "\n",
      "{\n",
      "  \"id\": \"chatcmpl-8OdteL587sxQQR10wCzkYh1u17ijP\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1700883926,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"A camel is a large mammal with a hump on its back. It is known for its ability to survive in harsh desert environments due to its ability to store water. Camels are commonly used as pack animals and can travel long distances without needing much water. They are also known for their distinctive long necks and eyelashes.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 120,\n",
      "    \"completion_tokens\": 68,\n",
      "    \"total_tokens\": 188\n",
      "  }\n",
      "}\n",
      "answer received in 9.581519842147827 seconds.\n"
     ]
    }
   ],
   "source": [
    "function_call_prompt(\"\"\"\n",
    "What is a camel?\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}