{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_for_knowledge_retrieval.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from projects.chatgpt.agents.LLMFunctionsAgent import LLMFunctionsAgent\n",
    "\n",
    "# configure the client's secret key\n",
    "with open('secret-key.txt', 'r') as file:\n",
    "    secret_key = file.read().strip()\n",
    "openai.api_key = secret_key\n",
    "\n",
    "max_tokens = 4092\n",
    "\n",
    "# automatically reload changes to imports\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-15T02:28:26.647046Z",
     "start_time": "2023-12-15T02:28:26.593392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import time\n",
    "def prompt(question):\n",
    "    start_time_seconds = time.time()\n",
    "    print(f\"asking chatgpt: {question}\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", #\"text-davinci-003\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions accurately, without making up facts.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "    )\n",
    "    # print(response)\n",
    "    choices = response.choices\n",
    "    choice = choices[0]\n",
    "    message = choice['message']\n",
    "    answer = message['content']\n",
    "    print(answer)\n",
    "    print(f\"answer received in {time.time() - start_time_seconds} seconds.\")\n",
    "\n",
    "def stream_prompt(question):\n",
    "    start_time_seconds = time.time()\n",
    "    print(f\"asking chatgpt: {question}\")\n",
    "    stream = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", #\"text-davinci-003\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions accurately, without making up facts.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    for output in stream:\n",
    "        choices = output['choices']\n",
    "        choice = choices[0]\n",
    "        delta = choice['delta']\n",
    "        if 'content' in delta:\n",
    "            print(delta['content'], end='')\n",
    "    print()\n",
    "    print(f\"answer received in {time.time() - start_time_seconds} seconds.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-15T02:28:29.154949Z",
     "start_time": "2023-12-15T02:28:29.101372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asking chatgpt: \n",
      "What is a camel?\n",
      "A camel is a large mammal that is native to the deserts of Asia and Africa. They are known for their distinctive hump on their back, which is a storage for fat reserves. Camels are well adapted to desert life, with long legs that help them navigate through sandy terrain, and wide, tough feet that prevent them from sinking. They have a unique ability to conserve water and can go for long periods without drinking. Camels are often used by humans for transportation and as pack animals.\n",
      "answer received in 7.581058979034424 seconds.\n"
     ]
    }
   ],
   "source": [
    "stream_prompt(\"\"\"\n",
    "What is a camel?\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-15T02:28:38.619864Z",
     "start_time": "2023-12-15T02:28:31.031965Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "\n",
      "---- found function with tool_data: find_financial_transactions\n",
      "---- found function with tool_data: get_user_details\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "llm_functions_agent = LLMFunctionsAgent(openai=openai)\n",
    "\n",
    "def inference(question):\n",
    "    llm_functions_agent.inference(question)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-15T02:25:45.639487Z",
     "start_time": "2023-12-15T02:25:45.550780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- inference ------------\n",
      "sending messages: [{'role': 'system', 'content': 'You are a helpful assistant that answers questions accurately, without making up facts.'}, {'role': 'user', 'content': '\\nWho is user Jason McAffee?\\n'}]\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAPIRemovedInV1\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mautoreload\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;43mWho is user Jason McAffee?\u001B[39;49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;43m\"\"\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m, in \u001B[0;36minference\u001B[0;34m(question)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minference\u001B[39m(question):\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mllm_functions_agent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/python-playground-v2/projects/chatgpt/agents/LLMFunctionsAgent.py:41\u001B[0m, in \u001B[0;36mLLMFunctionsAgent.inference\u001B[0;34m(self, question, conversation, start_time_seconds)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msending messages: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmessages\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# call chatgpt\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtools\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# print(response)\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# add the response to our conversation.  we may need to pass it back to chatgpt if a function is called.\u001B[39;00m\n\u001B[1;32m     45\u001B[0m conversation\u001B[38;5;241m.\u001B[39madd_chatgpt_response_to_messages(response)\n",
      "File \u001B[0;32m~/git/python-playground-v2/venv/lib/python3.9/site-packages/openai/lib/_old_api.py:39\u001B[0m, in \u001B[0;36mAPIRemovedInV1Proxy.__call__\u001B[0;34m(self, *_args, **_kwargs)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m_args: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m APIRemovedInV1(symbol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_symbol)\n",
      "\u001B[0;31mAPIRemovedInV1\u001B[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "inference(\"\"\"\n",
    "Who is user Jason McAffee?\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-15T02:25:50.875741Z",
     "start_time": "2023-12-15T02:25:50.763213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T23:11:43.055813Z",
     "start_time": "2023-11-26T23:11:43.025589Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
