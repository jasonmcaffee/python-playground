{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://blog.unrealspeech.com/how-to-use-whisper-cpp-in-python-complete-guide/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb118a44b2cfe6b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T16:04:22.205255Z",
     "start_time": "2024-04-28T16:04:19.692370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywhispercpp in /usr/local/lib/python3.11/site-packages (1.2.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from pywhispercpp) (1.25.0)\r\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/site-packages (from pywhispercpp) (0.25.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from pywhispercpp) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from pywhispercpp) (4.65.0)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/site-packages (from pywhispercpp) (3.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->pywhispercpp) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->pywhispercpp) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->pywhispercpp) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->pywhispercpp) (2023.5.7)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.11 -m pip install --upgrade pip\u001B[0m\r\n",
      "zsh:1: no matches found: pywhispercpp[examples]\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install whispercpp\n",
    "# !pip install whisper-cpp-python\n",
    "# !pip install ffmpeg\n",
    "# !pip install git+https://github.com/stlukey/whispercpp.py\n",
    "\n",
    "!pip install pywhispercpp\n",
    "!pip install pywhispercpp[examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisper_cpp_python'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwhisper_cpp_python\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Whisper\n\u001B[1;32m      2\u001B[0m whisper \u001B[38;5;241m=\u001B[39m Whisper(model_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./models/ggml-tiny.bin\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'whisper_cpp_python'"
     ]
    }
   ],
   "source": [
    "# from whisper_cpp_python import Whisper\n",
    "# whisper = Whisper(model_path=\"./models/ggml-tiny.bin\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:41:31.233728Z",
     "start_time": "2024-04-28T15:41:31.212818Z"
    }
   },
   "id": "bf7c518e5e905a32"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-28 10:08:40,114] {utils.py:38} INFO - No download directory was provided, models will be downloaded to /Users/jason/Library/Application Support/pywhispercpp/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "Downloading Model base.en ...: 100%|██████████| 141M/141M [00:12<00:00, 11.4MiB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-28 10:08:54,261] {utils.py:63} INFO - Model downloaded to /Users/jason/Library/Application Support/pywhispercpp/models/ggml-base.en.bin\n",
      "[2024-04-28 10:08:54,262] {model.py:221} INFO - Initializing the model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "whisper_init_from_file_with_params_no_state: loading model from '/Users/jason/Library/Application Support/pywhispercpp/models/ggml-base.en.bin'\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51864\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 512\n",
      "whisper_model_load: n_audio_head  = 8\n",
      "whisper_model_load: n_audio_layer = 6\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 512\n",
      "whisper_model_load: n_text_head   = 8\n",
      "whisper_model_load: n_text_layer  = 6\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 2 (base)\n",
      "whisper_model_load: adding 1607 extra tokens\n",
      "whisper_model_load: n_langs       = 99\n",
      "whisper_backend_init: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: AMD Radeon RX 6600\n",
      "ggml_metal_init: picking default device: AMD Radeon RX 6600\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: error: could not use bundle path to find ggml-metal.metal, falling back to trying cwd\n",
      "ggml_metal_init: loading 'ggml-metal.metal'\n",
      "ggml_metal_init: error: Error Domain=NSCocoaErrorDomain Code=260 \"The file “ggml-metal.metal” couldn’t be opened because there is no such file.\" UserInfo={NSFilePath=ggml-metal.metal, NSUnderlyingError=0x6000021a9710 {Error Domain=NSPOSIXErrorDomain Code=2 \"No such file or directory\"}}\n",
      "whisper_backend_init: ggml_backend_metal_init() failed\n",
      "whisper_model_load:      CPU buffer size =   147.46 MB\n",
      "whisper_model_load: model size    =  147.37 MB\n",
      "whisper_backend_init: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: AMD Radeon RX 6600\n",
      "ggml_metal_init: picking default device: AMD Radeon RX 6600\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: error: could not use bundle path to find ggml-metal.metal, falling back to trying cwd\n",
      "ggml_metal_init: loading 'ggml-metal.metal'\n",
      "ggml_metal_init: error: Error Domain=NSCocoaErrorDomain Code=260 \"The file “ggml-metal.metal” couldn’t be opened because there is no such file.\" UserInfo={NSFilePath=ggml-metal.metal, NSUnderlyingError=0x6000021a0810 {Error Domain=NSPOSIXErrorDomain Code=2 \"No such file or directory\"}}\n",
      "whisper_backend_init: ggml_backend_metal_init() failed\n",
      "whisper_init_state: kv self size  =   16.52 MB\n",
      "whisper_init_state: kv cross size =   18.43 MB\n",
      "whisper_init_state: compute buffer (conv)   =   14.86 MB\n",
      "whisper_init_state: compute buffer (encode) =   85.99 MB\n",
      "whisper_init_state: compute buffer (cross)  =    4.78 MB\n",
      "whisper_init_state: compute buffer (decode) =   96.48 MB\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "file.mp3",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpywhispercpp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m Model(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbase.en\u001B[39m\u001B[38;5;124m'\u001B[39m, n_threads\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m segments \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranscribe\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfile.mp3\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspeed_up\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m segment \u001B[38;5;129;01min\u001B[39;00m segments:\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(segment\u001B[38;5;241m.\u001B[39mtext)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pywhispercpp/model.py:118\u001B[0m, in \u001B[0;36mModel.transcribe\u001B[0;34m(self, media, n_processors, new_segment_callback, **params)\u001B[0m\n\u001B[1;32m    116\u001B[0m     media_path \u001B[38;5;241m=\u001B[39m Path(media)\u001B[38;5;241m.\u001B[39mresolve()\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m media_path\u001B[38;5;241m.\u001B[39mexists():\n\u001B[0;32m--> 118\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(media)\n\u001B[1;32m    119\u001B[0m     audio \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_audio(media_path)\n\u001B[1;32m    120\u001B[0m \u001B[38;5;66;03m# update params if any\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: file.mp3"
     ]
    }
   ],
   "source": [
    "from pywhispercpp.model import Model\n",
    "\n",
    "model = Model('base.en', n_threads=6)\n",
    "segments = model.transcribe('file.mp3', speed_up=True)\n",
    "for segment in segments:\n",
    "    print(segment.text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T16:08:54.517381Z",
     "start_time": "2024-04-28T16:08:36.177879Z"
    }
   },
   "id": "497b71da7bc70fb6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from op"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7508a856eb20c520"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
